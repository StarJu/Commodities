{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAYESIAN COMMODITY FUTURES INDICES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas            as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn           as sbn\n",
    "import numpy             as np\n",
    "import pyflux            as pf\n",
    "\n",
    "from helpers                       import best_of\n",
    "from itertools                     import product\n",
    "from pandas.tools.plotting         import autocorrelation_plot\n",
    "from scipy.stats                   import expon, laplace, t\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from matplotlib.collections        import PolyCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook  Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "sbn.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Fix Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat_file = './data/CommodityIndices.xlsx'\n",
    "skiprows = (2, 3, 4, 5)\n",
    "raw_data = pd.read_excel(dat_file, skiprows=skiprows, index_col=0, parse_cols='B:AE')\n",
    "\n",
    "raw_data.columns = [column[4:-2].rstrip() for column in raw_data.columns]\n",
    "raw_data.iloc[0] = 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index, Returns, and Volatility\n",
    "Pick any index by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name = 'Nickel'  # Name of index as string\n",
    "\n",
    "data = raw_data[name].resample('BQ').mean()\n",
    "\n",
    "fig, ax = plt.subplots(num=name+' Over the Aeons')\n",
    "data.plot(ax=ax, label=name)\n",
    "\n",
    "ax.legend(loc='best', frameon=True, fancybox=True, framealpha=0.8)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Relative index')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not exactly what you'd call a _stationary_ time series. So, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... let's look at quarterly returns instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "returns = 100 * data.pct_change(1).dropna()\n",
    "\n",
    "fig = plt.figure(num='Returns on '+name+' and their (Partial) Autocorrelation', figsize=(9.7, 10))\n",
    "return_ax = fig.add_subplot(311)\n",
    "aucorr_ax = fig.add_subplot(312)\n",
    "pacorr_ax = fig.add_subplot(313)\n",
    "\n",
    "returns.plot(ax=return_ax)\n",
    "return_ax.set_xlabel('Time')\n",
    "return_ax.set_ylabel('Quarterly returns')\n",
    "\n",
    "autocorrelation_plot(returns, ax=aucorr_ax)\n",
    "\n",
    "plot_pacf(returns, alpha=0.01, ax=pacorr_ax, linewidth=0.5)\n",
    "pacorr_ax.set_ylim(aucorr_ax.get_ylim())\n",
    "pacorr_ax.set_xlim(aucorr_ax.get_xlim())\n",
    "pacorr_ax.set_title('')\n",
    "pacorr_ax.set_xlabel('Lag')\n",
    "pacorr_ax.set_ylabel('Partial autocorrelation')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If neither autocorrelation nor partial autocorrelation significantly exceeds the confidence intervals at any lag, vanilla ARMA models are not going to do you much good. So let's also look at the *absolute* returns and _their_ (partial) autocorrelation next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute returns and their autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(num='Absolute Returns on '+name+' and their (Partial) Autocorrelation', figsize=(9.7, 10))\n",
    "return_ax = fig.add_subplot(311)\n",
    "aucorr_ax = fig.add_subplot(312)\n",
    "pacorr_ax = fig.add_subplot(313)\n",
    "\n",
    "returns.abs().plot(ax=return_ax)\n",
    "return_ax.set_xlabel('Time')\n",
    "return_ax.set_ylabel('Absolute quarterly returns')\n",
    "\n",
    "autocorrelation_plot(returns.abs(), ax=aucorr_ax);\n",
    "\n",
    "plot_pacf(returns.abs(), alpha=0.05, ax=pacorr_ax, linewidth=0.5)\n",
    "pacorr_ax.set_ylim(aucorr_ax.get_ylim())\n",
    "pacorr_ax.set_xlim(aucorr_ax.get_xlim())\n",
    "pacorr_ax.set_title('')\n",
    "pacorr_ax.set_xlabel('Lag')\n",
    "pacorr_ax.set_ylabel('Partial autocorrelation')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If either the autocorrelation or the partial autocorrelation significantly exceeds the confidence intervals at any lag, then GARCH-type models on the volatility might be what we are looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of (absolute) returns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(num='Distribution of (Absolute) Returns on '+name, figsize=(9.7, 4))\n",
    "returns_ax = fig.add_subplot(121)\n",
    "absrtns_ax = fig.add_subplot(122)\n",
    "\n",
    "sbn.distplot(returns, \n",
    "             bins=15, \n",
    "             kde=False, \n",
    "             fit=laplace, \n",
    "             fit_kws={'color': '#c44e52', 'label': 'Laplace'}, \n",
    "             ax=returns_ax);\n",
    "returns_ax.set_title('Quarterly Returns on '+name)\n",
    "returns_ax.set_xlabel('Value')\n",
    "returns_ax.set_ylabel('Frequency')\n",
    "\n",
    "sbn.distplot(returns.abs(), \n",
    "             bins=15, \n",
    "             kde=False, \n",
    "             fit=expon, \n",
    "             fit_kws={'color': '#c44e52'}, \n",
    "             color='#55a868', \n",
    "             ax=absrtns_ax); \n",
    "absrtns_ax.set_title('Absolute Quarterly Returns on '+name)\n",
    "absrtns_ax.set_xlabel('Absolute Value')\n",
    "absrtns_ax.set_ylabel('Frequency')\n",
    "\n",
    "x_lims = returns_ax.get_xlim()\n",
    "x_vals = np.linspace(*x_lims, 200)\n",
    "params = t.fit(returns)\n",
    "returns_ax.plot(x_vals, t.pdf(x_vals, *params), label='Students-t')\n",
    "returns_ax.legend(loc='best', frameon=True, fancybox=True, framealpha=0.8)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the tails of the (absolute) returns are *far* too fat for a Gaussian process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## A Grand Tour of the Bayesian  `PyFlux` Package\n",
    "In case you are wondering why we never touch the _priors_, it is because they seem to be fine for the data at hand. Nothing could express my belief better. Note also, that we will not consider GARCH-type models here, as these are already dealt with in other notebooks at length.\n",
    "### ARMA models\n",
    "#### Set up lag ranges and scan through all models to find the one with minimal BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maximumlag = 5  # Up to which lag-order should we test models?\n",
    "\n",
    "timeseries = returns.values\n",
    "drop_first = lambda lag_combi: timeseries[maximumlag - max(lag_combi.values()):]\n",
    "lag_ranges = {'ar': range(maximumlag+1),\n",
    "              'ma': range(maximumlag+1)}\n",
    "lag_combis = (dict(zip(lag_ranges.keys(), values)) for values in product(*lag_ranges.values()))\n",
    "ARMAmodels = (pf.ARIMA(drop_first(lags), **lags, family=pf.t()) for lags in lag_combis)\n",
    "\n",
    "best_ARMA_model = best_of(ARMAmodels)\n",
    "best_ARMA_model.fit().summary(transformed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Black Box Variational Inference and check its convergence\n",
    "Consider increasing the number of iterations if you are not happy with what you see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ARMAresults = best_ARMA_model.fit(method='BBVI', map_start=True, record_elbo=True, iterations=3000)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(ARMAresults.elbo_records)\n",
    "ax.set_xlabel('Iteration Number')\n",
    "ax.set_ylabel('ELBO')\n",
    "\n",
    "ARMAresults.summary(transformed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot fit to returns and forecast for a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_ARMA_model.plot_fit(figsize=(9.7, 5))\n",
    "best_ARMA_model.plot_predict(h=4, figsize=(9.7, 5))\n",
    "children = plt.gca().get_children() \n",
    "_ = [child.set_facecolor('C0') for child in children if isinstance(child, PolyCollection)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GARCH models\n",
    "#### Set up model types and lag ranges to be scanned and find the one with minimal BIC\n",
    "**Note**: SEGARCH and SEGARCHM models don't seem to always converge when fitted with MLE. Check before you include them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maximumlag = 4  # Up to which lag-order should we test models?\n",
    "\n",
    "timeseries = returns.values\n",
    "drop_first = lambda lag_combi: timeseries[maximumlag - max(lag_combi.values()):]\n",
    "lag_ranges = {'p': range(1, maximumlag+1),\n",
    "              'q': range(maximumlag+1)}\n",
    "modeltypes = (pf.GARCH, pf.EGARCH, pf.LMEGARCH)  # and pf.SEGARCH, pf.SEGARCHM, pf.EGARCHM ?\n",
    "lag_combis = (dict(zip(lag_ranges.keys(), values)) for values in product(*lag_ranges.values()))\n",
    "ARCHmodels = [model(drop_first(lags), **lags) for lags in lag_combis for model in modeltypes]\n",
    "\n",
    "best_model = best_of(ARCHmodels)\n",
    "best_leveraged_model = best_of(ARCHmodels, leverage=True)\n",
    "\n",
    "best_results = best_model.fit()\n",
    "best_leveraged_results = best_leveraged_model.fit()\n",
    "\n",
    "if best_results.bic < best_leveraged_results.bic:\n",
    "    best_ARCH_model = best_model\n",
    "    best_results.summary(transformed=False)\n",
    "else:\n",
    "    best_ARCH_model = best_leveraged_model\n",
    "    best_leveraged_results.summary(transformed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Black Box Variational Inference and check its convergence\n",
    "Consider increasing the number of iterations if you are not happy with what you see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ARCHresults = best_ARCH_model.fit(method='M-H', map_start=True, record_elbo=True, nsims=30000)\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.plot(ARCHresults.elbo_records)\n",
    "#ax.set_xlabel('Iteration Number')\n",
    "#ax.set_ylabel('ELBO')\n",
    "best_ARCH_model.latent_variables.trace_plot(figsize=(9.7, 10))\n",
    "ARCHresults.summary(transformed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot fit to volatility and forecast for a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_ARCH_model.plot_fit(figsize=(9.7, 5))\n",
    "best_ARCH_model.plot_predict(h=4, figsize=(9.7, 5))\n",
    "children = plt.gca().get_children() \n",
    "_ = [child.set_facecolor('C0') for child in children if isinstance(child, PolyCollection)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAS models on the volatility ...\n",
    "#### Set up lag ranges and scan through all models to find the one with minimal BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maximumlag = 4  # Up to which lag-order should we test models?\n",
    "\n",
    "timeseries = returns.abs().values\n",
    "drop_first = lambda lag_combi: timeseries[maximumlag - max(lag_combi.values()):]\n",
    "lag_ranges = {'ar': range(maximumlag+1),\n",
    "              'sc': range(maximumlag+1)}\n",
    "lag_combis = (dict(zip(lag_ranges.keys(), values)) for values in product(*lag_ranges.values()))\n",
    "GAS_models = (pf.GAS(drop_first(lags), **lags, family=pf.Poisson()) for lags in lag_combis)\n",
    "\n",
    "best_GAS_model = best_of(GAS_models)\n",
    "best_GAS_model.fit().summary(transformed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample posterior probability with MCMC\n",
    "Consider increasing the number of simulated steps if the results are not converged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GASresults = best_GAS_model.fit(method='M-H', map_start=True, record_elbo=True, nsims=20000)\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.plot(GASresults.elbo_records)\n",
    "#ax.set_xlabel('Iteration Number')\n",
    "#ax.set_ylabel('ELBO')\n",
    "best_GAS_model.latent_variables.trace_plot(figsize=(9.7, 10))\n",
    "GASresults.summary(transformed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot fit to volatility and forecast for a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_GAS_model.plot_fit(figsize=(9.7, 8))\n",
    "best_GAS_model.plot_predict(h=4, figsize=(9.7, 6))\n",
    "children = plt.gca().get_children() \n",
    "_ = [child.set_facecolor('C0') for child in children if isinstance(child, PolyCollection)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... and on the returns\n",
    "#### Set up lag ranges and scan through all models to find the one with minimal BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maximumlag = 4  # Up to which lag-order should we test models?\n",
    "\n",
    "timeseries = returns.values\n",
    "drop_first = lambda lag_combi: timeseries[maximumlag - max(lag_combi.values()):]\n",
    "lag_ranges = {'ar': range(maximumlag+1),\n",
    "              'sc': range(maximumlag+1)}\n",
    "lag_combis = (dict(zip(lag_ranges.keys(), values)) for values in product(*lag_ranges.values()))\n",
    "GAS_models = (pf.GAS(drop_first(lags), **lags, family=pf.t()) for lags in lag_combis)\n",
    "\n",
    "best_GAS_model = best_of(GAS_models)\n",
    "best_GAS_model.fit().summary(transformed=False)\n",
    "#best_GAS_model.adjust_prior(4, pf.InverseGamma(10.0, 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Black Box Variational Inference and check its convergence\n",
    "Consider increasing the number of iterations if the you are not happy with what you see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GASresults = best_GAS_model.fit(method='BBVI', map_start=True, record_elbo=True, iterations=3000)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(GASresults.elbo_records)\n",
    "ax.set_xlabel('Iteration Number')\n",
    "ax.set_ylabel('ELBO')\n",
    "\n",
    "GASresults.summary(transformed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot fit to returns and forecast for a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_GAS_model.plot_fit(figsize=(9.7, 8))\n",
    "best_GAS_model.plot_predict(h=4, figsize=(9.7, 6))\n",
    "children = plt.gca().get_children() \n",
    "_ = [child.set_facecolor('C0') for child in children if isinstance(child, PolyCollection)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAS local-level model on the volatility\n",
    "#### Find maximum-likelihood parameters first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timeseries = returns.abs().values\n",
    "GASLLmodel = pf.GASLLEV(timeseries, pf.Poisson())\n",
    "GASLLEVres = GASLLmodel.fit()\n",
    "GASLLEVres.summary(transformed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample posterior probability with MCMC\n",
    "Consider increasing the number of simulated steps if the results are not converged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GASLLEVres = GASLLmodel.fit(method='M-H', map_start=True, nsims=10000)\n",
    "GASLLmodel.latent_variables.trace_plot(figsize=(9.7, 4))\n",
    "GASLLEVres.summary(transformed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot fit to volatility and forecast for a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GASLLmodel.plot_fit(figsize=(9.7, 8))\n",
    "GASLLmodel.plot_predict(h=4, figsize=(9.7, 5))\n",
    "children = plt.gca().get_children() \n",
    "_ = [child.set_facecolor('C0') for child in children if isinstance(child, PolyCollection)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GP-NARX models on the returns ...\n",
    "#### Set up parameter ranges and scan through all models to find the one with minimal BIC\n",
    "Note that not all kernels always lead to well-conditioned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_lag = 4  # Up to which lag-order should we test models?\n",
    "\n",
    "tseries = returns.values\n",
    "without = lambda ar: tseries[max_lag - ar:]\n",
    "ar_lags = range(1, max_lag+1)\n",
    "kernels = (pf.SquaredExponential(), pf.OrnsteinUhlenbeck(), pf.Periodic())  # maybe also pf.RationalQuadratic()\n",
    "GPNARXs = (pf.GPNARX(without(lag), lag, kernel) for lag in ar_lags for kernel in kernels)\n",
    "\n",
    "best_GPNARX_model = best_of(GPNARXs)\n",
    "nkernel = str(best_GPNARX_model.kernel).split('.')[3].split(' ')[0]\n",
    "results = best_GPNARX_model.fit()\n",
    "results.summary(transformed=False)\n",
    "print('BEST KERNEL IS', nkernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot fit to returns and forecast for a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_GPNARX_model.plot_fit(figsize=(9.7, 8))\n",
    "best_GPNARX_model.plot_predict(h=4, figsize=(9.7, 5))\n",
    "children = plt.gca().get_children() \n",
    "_ = [child.set_facecolor('C0') for child in children if isinstance(child, PolyCollection)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAR model\n",
    "#### Set up parameter ranges and scan through all models to find the one with minimal BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maximumlag = 12  # Up to which lag-order should we test models?\n",
    "\n",
    "timeseries = 100 * raw_data.loc[:, 'Energy':'Livestock'].resample('BQ').mean().pct_change(1).dropna()\n",
    "drop_first = lambda ar_lag: timeseries.iloc[maximumlag - ar_lag:, :]\n",
    "lag_orders = range(1, maximumlag+1)\n",
    "VAR_models = (pf.VAR(drop_first(lag), lag) for lag in lag_orders)\n",
    "\n",
    "min_bic, best_VAR_model = min((model.fit().bic, model) for model in VAR_models)\n",
    "best_VAR_model.fit().summary(transformed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Black Box Variational Inference and check its convergence\n",
    "Consider increasing the number of iterations if the you are not happy with what you see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VARresults = best_VAR_model.fit(method='BBVI', map_start=True, record_elbo=True, iterations=5000)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(VARresults.elbo_records)\n",
    "ax.set_xlabel('Iteration Number')\n",
    "ax.set_ylabel('ELBO')\n",
    "\n",
    "VARresults.summary(transformed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot fit to returns and forecast for a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_VAR_model.plot_fit(figsize=(9.7, 4))\n",
    "best_VAR_model.plot_predict(h=4, figsize=(9.7, 4))\n",
    "for figure in map(plt.figure, plt.get_fignums()[-5:]):\n",
    "    children = plt.gca().get_children()\n",
    "    _ = [child.set_facecolor('C0') for child in children if isinstance(child, PolyCollection)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Concluding remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there are yet more models available in the `PyFlux` package, it does not make sense to apply them all on the financial data at hand. In partiuclar, quarterly returns have neither a \"local level\" nor \"local linear trend\". Likewise, the raw index the data is not well described by such models because the volatility is not exactly constant. Lastly, the nonlinear local level models available in `PyFlux` do not describe the volatility well for some reason. So, while a fascinating class of models, they are not included here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What could work: Brent Crude (no GAS on returns), Aluminum (no GAS on returns), Copper (no GAS on returns), Zinc(no Gas returns), Silver(no Gas returns), Wheat(no Gas returns)\n",
    "\n",
    "Nickel is gut?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
